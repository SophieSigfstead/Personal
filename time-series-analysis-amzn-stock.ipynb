{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-07T00:34:22.562361Z","iopub.execute_input":"2022-10-07T00:34:22.562778Z","iopub.status.idle":"2022-10-07T00:34:22.570556Z","shell.execute_reply.started":"2022-10-07T00:34:22.562746Z","shell.execute_reply":"2022-10-07T00:34:22.569637Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-stock-prices-may-2017-to-may-2022/AMZN.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading Data and Set-Up","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/amazon-stock-prices-may-2017-to-may-2022/AMZN.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:22.572257Z","iopub.execute_input":"2022-10-07T00:34:22.573132Z","iopub.status.idle":"2022-10-07T00:34:22.602294Z","shell.execute_reply.started":"2022-10-07T00:34:22.573101Z","shell.execute_reply":"2022-10-07T00:34:22.601237Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:22.603795Z","iopub.execute_input":"2022-10-07T00:34:22.604437Z","iopub.status.idle":"2022-10-07T00:34:22.639682Z","shell.execute_reply.started":"2022-10-07T00:34:22.604389Z","shell.execute_reply":"2022-10-07T00:34:22.638847Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         Date       Open       High        Low      Close  Adj Close    Volume\n0  2017-06-01  49.929501  49.949501  49.568501  49.797501  49.797501  49096000\n1  2017-06-02  49.949501  50.424000  49.783501  50.336498  50.336498  75046000\n2  2017-06-05  50.361500  50.660500  50.175499  50.567001  50.567001  54398000\n3  2017-06-06  50.599998  50.825001  50.062500  50.150002  50.150002  66928000\n4  2017-06-07  50.297501  50.512501  50.099998  50.503502  50.503502  56460000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-06-01</td>\n      <td>49.929501</td>\n      <td>49.949501</td>\n      <td>49.568501</td>\n      <td>49.797501</td>\n      <td>49.797501</td>\n      <td>49096000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-06-02</td>\n      <td>49.949501</td>\n      <td>50.424000</td>\n      <td>49.783501</td>\n      <td>50.336498</td>\n      <td>50.336498</td>\n      <td>75046000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-06-05</td>\n      <td>50.361500</td>\n      <td>50.660500</td>\n      <td>50.175499</td>\n      <td>50.567001</td>\n      <td>50.567001</td>\n      <td>54398000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-06-06</td>\n      <td>50.599998</td>\n      <td>50.825001</td>\n      <td>50.062500</td>\n      <td>50.150002</td>\n      <td>50.150002</td>\n      <td>66928000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-06-07</td>\n      <td>50.297501</td>\n      <td>50.512501</td>\n      <td>50.099998</td>\n      <td>50.503502</td>\n      <td>50.503502</td>\n      <td>56460000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:22.641622Z","iopub.execute_input":"2022-10-07T00:34:22.642440Z","iopub.status.idle":"2022-10-07T00:34:22.682509Z","shell.execute_reply.started":"2022-10-07T00:34:22.642410Z","shell.execute_reply":"2022-10-07T00:34:22.681290Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"              Open         High          Low        Close    Adj Close  \\\ncount  1259.000000  1259.000000  1259.000000  1259.000000  1259.000000   \nmean    112.712150   113.962250   111.290146   112.638289   112.638289   \nstd      41.589328    42.096757    41.022137    41.521249    41.521249   \nmin      47.000000    47.431499    46.349998    46.930000    46.930000   \n25%      82.564251    83.682998    81.300998    82.778748    82.778748   \n50%      95.899002    96.611504    94.828499    95.449501    95.449501   \n75%     158.343750   159.924003   156.199997   158.086998   158.086998   \nmax     187.199997   188.654007   184.839493   186.570496   186.570496   \n\n             Volume  \ncount  1.259000e+03  \nmean   8.661014e+07  \nstd    4.156922e+07  \nmin    1.762600e+07  \n25%    5.843600e+07  \n50%    7.475200e+07  \n75%    1.025520e+08  \nmax    3.313000e+08  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1259.000000</td>\n      <td>1259.000000</td>\n      <td>1259.000000</td>\n      <td>1259.000000</td>\n      <td>1259.000000</td>\n      <td>1.259000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>112.712150</td>\n      <td>113.962250</td>\n      <td>111.290146</td>\n      <td>112.638289</td>\n      <td>112.638289</td>\n      <td>8.661014e+07</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>41.589328</td>\n      <td>42.096757</td>\n      <td>41.022137</td>\n      <td>41.521249</td>\n      <td>41.521249</td>\n      <td>4.156922e+07</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>47.000000</td>\n      <td>47.431499</td>\n      <td>46.349998</td>\n      <td>46.930000</td>\n      <td>46.930000</td>\n      <td>1.762600e+07</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>82.564251</td>\n      <td>83.682998</td>\n      <td>81.300998</td>\n      <td>82.778748</td>\n      <td>82.778748</td>\n      <td>5.843600e+07</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>95.899002</td>\n      <td>96.611504</td>\n      <td>94.828499</td>\n      <td>95.449501</td>\n      <td>95.449501</td>\n      <td>7.475200e+07</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>158.343750</td>\n      <td>159.924003</td>\n      <td>156.199997</td>\n      <td>158.086998</td>\n      <td>158.086998</td>\n      <td>1.025520e+08</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>187.199997</td>\n      <td>188.654007</td>\n      <td>184.839493</td>\n      <td>186.570496</td>\n      <td>186.570496</td>\n      <td>3.313000e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Feature Engineering\n- Adding date and time based features\n- Adding rolling mean averages for close, high, low, volume\n- Adding lag features for close \n- Removing columns from data set to avoid leakage - the purpose of the model is to predict the given day's stock close, and so data from that day (High, Low, etc.) would not be available yet for predictions. ","metadata":{}},{"cell_type":"code","source":"\n# adding date based features: day of week, day of month, day of year \n\ndata['Date'] = pd.to_datetime(data['Date'])\ndata['Day of week'] = data['Date'].dt.weekday\ndata['Day of month'] = data['Date'].dt.day\ndata['Month'] = data['Date'].dt.month\ndata['Year'] = data['Date'].dt.year\n\n# rolling averages for days = 7, 30, 90, 180, 365\n\ndata[\"7d Mean Close\"] = data['Close'].rolling(window = 5).mean() # 5 business days = 1 wk\ndata[\"30d Mean Close\"] = data['Close'].rolling(window = 20).mean() # 20 business days = 1 mo\ndata[\"90d Mean Close\"] = data['Close'].rolling(window = 60).mean() # 60 business days = 3 mo\ndata[\"120d Mean Close\"] = data['Close'].rolling(window = 120).mean() #120 business days = 6 mo\n\n# adding lag features: Close on (date - 1), (date-2), 3,4,5,7,14,21,30,60,90,180, 365\ndata['Close-1'] = data['Close'].shift(periods=1)\ndata['Close-2'] = data['Close'].shift(periods=2)\ndata['Close-3'] = data['Close'].shift(periods=3)\ndata['Close-4'] = data['Close'].shift(periods=4)\ndata['Close-5'] = data['Close'].shift(periods=5)\ndata['Close-7'] = data['Close'].shift(periods=7)\ndata['Close-14'] = data['Close'].shift(periods=14)\ndata['Close-21'] = data['Close'].shift(periods=21)\ndata['Close-30'] = data['Close'].shift(periods=30)\ndata['Close-60'] = data['Close'].shift(periods=60)\ndata['Close-90'] = data['Close'].shift(periods=90)\n\n# Adding rolling averages for high, low and volume\ndata[\"7d Mean High\"] = data['High'].rolling(window = 5).mean() # 5 business days = 1 wk\ndata[\"30d Mean High\"] = data['High'].rolling(window = 20).mean() # 20 business days = 1 mo\ndata[\"90d Mean High\"] = data['High'].rolling(window = 60).mean() # 60 business days = 3 mo\ndata[\"120d Mean High\"] = data['High'].rolling(window = 120).mean() #120 business days = 6 mo\n\ndata[\"7d Mean Low\"] = data['Low'].rolling(window = 5).mean() # 5 business days = 1 wk\ndata[\"30d Mean Low\"] = data['Low'].rolling(window = 20).mean() # 20 business days = 1 mo\ndata[\"90d Mean Low\"] = data['Low'].rolling(window = 60).mean() # 60 business days = 3 mo\ndata[\"120d Mean Low\"] = data['Low'].rolling(window = 120).mean() #120 business days = 6 mo\n\ndata[\"7d Mean Volume\"] = data['Volume'].rolling(window = 5).mean() # 5 business days = 1 wk\ndata[\"30d Mean Volume\"] = data['Volume'].rolling(window = 20).mean() # 20 business days = 1 mo\ndata[\"90d Mean Volume\"] = data['Volume'].rolling(window = 60).mean() # 60 business days = 3 mo\ndata[\"120d Mean Volume\"] = data['Volume'].rolling(window = 120).mean() #120 business days = 6 mo\n\n\n# Will only train models on data with all features intact, so will exclude the first 120 data points\nfull_data = data.drop(index = range(119)) \nfull_data = full_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:22.684057Z","iopub.execute_input":"2022-10-07T00:34:22.684378Z","iopub.status.idle":"2022-10-07T00:34:22.731095Z","shell.execute_reply.started":"2022-10-07T00:34:22.684350Z","shell.execute_reply":"2022-10-07T00:34:22.730108Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Dropping Features to Limit Data Leakage","metadata":{}},{"cell_type":"code","source":"# To avoid leakage must drop features that will be unavailable at time of prediction\nX = full_data.drop(columns = ['Close', 'Adj Close', 'Open', 'High', 'Low', 'Volume']) \nY = full_data['Close']\n# Adding index in place of date\nX ['index'] = X.index\n# Removing dates so XGBoost will work\nX_no_dates = X.drop(columns = ['Date']).to_numpy()\nY_no_dates = Y.drop(columns = ['Date']).to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:37:32.417813Z","iopub.execute_input":"2022-10-07T00:37:32.418243Z","iopub.status.idle":"2022-10-07T00:37:32.428352Z","shell.execute_reply.started":"2022-10-07T00:37:32.418209Z","shell.execute_reply":"2022-10-07T00:37:32.427492Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Creating a simple XGBoost Regression Model \nThis will have a high error value but will serve as a comparison for the cross-validated regression and prophet models","metadata":{}},{"cell_type":"code","source":"## Creating a manual split (must allocate indexes manually to prevent shuffling)\nX_train = X_no_dates[0:800]\nX_test = X_no_dates[800:1139]\nY_train = Y_no_dates[0:800]\nY_test = Y_no_dates[800:1139]\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:39:06.226307Z","iopub.execute_input":"2022-10-07T00:39:06.226727Z","iopub.status.idle":"2022-10-07T00:39:06.233007Z","shell.execute_reply.started":"2022-10-07T00:39:06.226693Z","shell.execute_reply":"2022-10-07T00:39:06.231848Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from xgboost.sklearn import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nmodel = XGBRegressor()\nmodel.fit(X_train, Y_train)\npreds = model.predict(X_test)\n\nmse_xgboost = mean_squared_error (preds, Y_test)\nprint(mse_xgboost)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:39:28.498407Z","iopub.execute_input":"2022-10-07T00:39:28.498771Z","iopub.status.idle":"2022-10-07T00:39:29.155198Z","shell.execute_reply.started":"2022-10-07T00:39:28.498742Z","shell.execute_reply":"2022-10-07T00:39:29.154262Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"76.80376326906087\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Adding Cross Validation using a Rolling 120-day Window \nUsing an rolling window to train the model (implementing manually as having issues importing sktime to env), generates folds across an rolling window. The length of the training series remains constant, with each subsequent fold retaining the 120 bus days history up to that point. The testing series remains the same length throughout. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nfrom statistics import mean\n\ni = 0\nall_mse = []\n\nfor train_index, test_index in tscv.split(X):\n    while i+180 < len(X):\n        X_train, X_test = X_no_dates[i:i+120], X_no_dates[i+120:i+180]\n        Y_train, Y_test = Y_no_dates[i:i+120], Y_no_dates[i+120:i+180]\n        model = XGBRegressor()\n        model.fit(X_train, Y_train)\n        preds = model.predict(X_test)\n        mse = mean_squared_error (Y_test, preds)\n        all_mse.append(mse)\n        i = i + 60\n\nprint(mean(all_mse))\n    \n    \n#for train_index, test_index in tscv.split(X):\n#    cv_train, cv_test = \n    \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:44:20.466952Z","iopub.execute_input":"2022-10-07T00:44:20.467335Z","iopub.status.idle":"2022-10-07T00:44:27.757648Z","shell.execute_reply.started":"2022-10-07T00:44:20.467306Z","shell.execute_reply":"2022-10-07T00:44:27.756487Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"67.72227610136395\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-10-06T05:09:05.856699Z","iopub.status.idle":"2022-10-06T05:09:05.857120Z","shell.execute_reply.started":"2022-10-06T05:09:05.856925Z","shell.execute_reply":"2022-10-06T05:09:05.856944Z"}}},{"cell_type":"markdown","source":"# Facebook Prophet Approach ","metadata":{}},{"cell_type":"code","source":"!pip install prophet;","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:23.568583Z","iopub.status.idle":"2022-10-07T00:34:23.569828Z","shell.execute_reply.started":"2022-10-07T00:34:23.569516Z","shell.execute_reply":"2022-10-07T00:34:23.569545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from prophet import Prophet\n# dropping cols to avoid leakage\nfull_data_prophet = full_data.drop(columns = ['Adj Close']) \nfull_data_prophet.rename(columns={'Date':'ds','Close':'y'},inplace=True)\nfull_data_prophet['ds'] = pd.to_datetime(full_data_prophet['ds'])\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:23.571551Z","iopub.status.idle":"2022-10-07T00:34:23.572434Z","shell.execute_reply.started":"2022-10-07T00:34:23.572152Z","shell.execute_reply":"2022-10-07T00:34:23.572179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will use a rolling 120 day prophet model to predict the following day \nfrom sklearn.metrics import mean_squared_error\npreds_vs_actual = pd.DataFrame(columns = ['Actual', 'Predicted'], index = [0,1,2,3,4,5,6,7,8,9])\n\nfor i in range(0,10): #for i in range(0,len(full_data_prophet)):\n    rolling_train_data = full_data_prophet.iloc[0+i:240+i,:] #0-120, 1-121, ...\n    model = Prophet()\n    model.fit(full_data_prophet)\n    days_left = len(full_data_prophet) - i \n    future_dates = model.make_future_dataframe(periods=1, freq='D') # MUST CHANGE to get only next day pred\n    forecast = model.predict(future_dates)\n    preds_vs_actual['Actual'][i] = Y[i]\n    preds_vs_actual['Predicted'][i]= forecast['yhat'][0]\n    i=i+1\n    \npreds_vs_actual.head()\nmse = mean_squared_error (preds_vs_actual['Actual'], preds_vs_actual['Predicted'])","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:23.574030Z","iopub.status.idle":"2022-10-07T00:34:23.574882Z","shell.execute_reply.started":"2022-10-07T00:34:23.574583Z","shell.execute_reply":"2022-10-07T00:34:23.574610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mse)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T00:34:23.576424Z","iopub.status.idle":"2022-10-07T00:34:23.577249Z","shell.execute_reply.started":"2022-10-07T00:34:23.577010Z","shell.execute_reply":"2022-10-07T00:34:23.577036Z"},"trusted":true},"execution_count":null,"outputs":[]}]}